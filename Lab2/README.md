# Лабораторная работа №2: Многослойный персептрон

## Цель работы

Изучение топологии и алгоритма функционирования многослойного персептрона. Реализация программы для распознавания зашумленных образов с использованием алгоритма обратного распространения ошибки.

## Теоретические сведения

Многослойный персептрон — это нейронная сеть с прямым распространением сигнала, обучаемая с учителем. Способна аппроксимировать любую непрерывную функцию.

### Архитектура сети

```
    Входной слой        Скрытый слой        Выходной слой
    (36 нейронов)       (20 нейронов)       (5 нейронов)
    
    ┌───┐               ┌───┐               ┌───┐
    │x₁ │──────────────►│h₁ │──────────────►│y₁ │ → Класс N
    └───┘               └───┘               └───┘
    ┌───┐               ┌───┐               ┌───┐
    │x₂ │──────────────►│h₂ │──────────────►│y₂ │ → Класс F
    └───┘               └───┘               └───┘
      ⋮                   ⋮                   ⋮
    ┌───┐               ┌───┐               ┌───┐
    │x₃₆│──────────────►│h₂₀│──────────────►│y₅ │ → Класс D
    └───┘               └───┘               └───┘
```

### Основные формулы

**Сигмоидная функция:**
```
f(x) = 1 / (1 + e^(-x))
```

**Обратное распространение ошибки:**
```
δ_k = (y_k^target - y_k) × f'(S_k)
w_jk := w_jk + α × δ_k × h_j
```

## Вариант задания

**Вариант 2:** Буквы **N**, **F**, **I**, **P**, **D** (размер 6×6)

## Требования

- Компилятор C++ с поддержкой C++17 (g++ 8+, clang++ 7+)
- Стандартная библиотека C++ (filesystem)

## Сборка и запуск

### 1. Компиляция

```bash
cd Lab2
g++ -std=c++17 solution.cpp -o solution
```

### 2. Запуск с выводом в консоль

```bash
./solution
```

### 3. Запуск с сохранением вывода в файл

```bash
# Сохранить вывод в файл (без отображения в консоли)
./solution > output.txt

# Сохранить вывод в файл И отобразить в консоли
./solution | tee output.txt

# Сохранить вывод вместе с ошибками
./solution > output.txt 2>&1
```

### 4. Компиляция отчёта LaTeX

```bash
xelatex report.tex
```

Требуется XeLaTeX и шрифты DejaVu.

## Структура файлов

```
Lab2/
├── README.md           # Этот файл
├── description.md      # Подробное описание задания
├── solution.cpp        # Исходный код решения
├── solution            # Скомпилированная программа
├── report.tex          # Отчет в формате LaTeX
├── report.pdf          # Скомпилированный отчет
├── output.txt          # Вывод программы (после запуска)
└── patterns/           # Эталонные образы
    ├── N.txt           # Буква N
    ├── F.txt           # Буква F
    ├── I.txt           # Буква I
    ├── P.txt           # Буква P
    └── D.txt           # Буква D
```

## Выходные файлы

После запуска программы создаются:

| Файл | Описание |
|------|----------|
| `output.txt` | Полный вывод программы (при использовании `> output.txt`) |

## Пример вывода программы

```
========================================================
    ЛАБОРАТОРНАЯ РАБОТА №2: МНОГОСЛОЙНЫЙ ПЕРСЕПТРОН
    Вариант 2: буквы N, F, I, P, D
========================================================

1. Загрузка эталонных образов из patterns/...
   Загружено 5 паттернов

2. Создание обучающей выборки...
   Создано 5 обучающих примеров

3. Обучение многослойного персептрона...
   Обучение завершено за 1542 эпох

4. Тестирование на идеальных образах:
======================================

┌─────────────────────────────────┐
│ Распознаваемый образ (6×6):    │
│   ■ □ □ □ □ ■                  │
│   ■ □ □ □ □ ■                  │
│   ■ ■ □ □ □ ■                  │
│   ■ □ ■ □ □ ■                  │
│   ■ □ □ ■ □ ■                  │
│   ■ □ □ □ ■ ■                  │
├─────────────────────────────────┤
│ Процент подобия:               │
│   Класс 1 (N): 99.2%  ◄── Распознан
│   Класс 2 (F): 0.1%            │
│   Класс 3 (I): 0.3%            │
│   Класс 4 (P): 0.2%            │
│   Класс 5 (D): 0.2%            │
└─────────────────────────────────┘
```

## Параметры сети

| Параметр | Значение |
|----------|----------|
| Входные нейроны | 36 (6×6) |
| Скрытые нейроны | 20 |
| Выходные нейроны | 5 |
| Скорость обучения α | 0.5 |
| Скорость обучения β | 0.5 |
| Макс. ошибка | 0.01 |

## Выводы

1. Многослойный персептрон успешно обучен на 5 классах образов
2. Сеть способна распознавать зашумленные образы при шуме до 30-40%
3. Процент подобия показывает уверенность сети в каждом классе
4. Обучение занимает 500-3000 эпох в зависимости от начальной инициализации
