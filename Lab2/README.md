# Лабораторная работа №2: Многослойный персептрон

## Цель работы

Изучение топологии и алгоритма функционирования многослойного персептрона. Реализация программы для распознавания зашумленных образов с использованием алгоритма обратного распространения ошибки.

## Теоретические сведения

Многослойный персептрон — это сеть с прямым распространением сигнала (без обратных связей), обучаемая с учителем. Способна аппроксимировать любую непрерывную функцию или границу между классами.

### Архитектура сети

```
    Входной слой      Скрытый слой       Выходной слой
    (36 нейронов)     (20 нейронов)      (5 нейронов)
    
         x₁ ──────────┬─────────────────┬────────────► y₁ (N)
          │           │                 │
          │    ┌───┐  │         ┌───┐   │    ┌───┐
          ├───►│ 1 │──┼────────►│ 1 │───┼───►│ 1 │
          │    └───┘  │         └───┘   │    └───┘
          │           │                 │
         x₂ ─────┬────┤         ┌───┐   │    ┌───┐
          │      │    ├────────►│ 2 │───┼───►│ 2 │───► y₂ (F)
          │      │    │         └───┘   │    └───┘
          │      │    │                 │
         ...    ...  ...        ...    ...   ...
          │      │    │                 │
          │      │    │         ┌───┐   │    ┌───┐
         x₃₆────►└────┴────────►│20 │───┴───►│ 5 │───► y₅ (D)
                               └───┘        └───┘
                                              ↑
                              Сигмоидная функция активации
```

### Основные формулы

**Скрытый слой:**
```
g_j = sigmoid(Σ(i=1 to n) v_ij × x_i + Q_j)
```

**Выходной слой:**
```
y_k = sigmoid(Σ(j=1 to h) w_jk × g_j + T_k)
```

**Сигмоидная функция:**
```
sigmoid(x) = 1 / (1 + exp(-x))
```

**Обратное распространение ошибки:**
```
w_jk := w_jk + α × y_k × (1 - y_k) × d_k × g_j
v_ij := v_ij + β × g_j × (1 - g_j) × e_j × x_i
```

## Вариант задания

**Вариант 2:** Буквы **N**, **F**, **I**, **P**, **D** (размер 6×6)

### Эталонные образы

```
Буква N (6×6):        Буква F (6×6):        Буква I (6×6):
■ □ □ □ □ ■          ■ ■ ■ ■ ■ ■          ■ ■ ■ ■ ■ ■
■ □ □ □ □ ■          ■ □ □ □ □ □          □ □ ■ ■ □ □
■ ■ □ □ □ ■          ■ □ □ □ □ □          □ □ ■ ■ □ □
■ □ ■ □ □ ■          ■ ■ ■ ■ □ □          □ □ ■ ■ □ □
■ □ □ ■ □ ■          ■ □ □ □ □ □          □ □ ■ ■ □ □
■ □ □ □ ■ ■          ■ □ □ □ □ □          ■ ■ ■ ■ ■ ■

Буква P (6×6):        Буква D (6×6):
■ ■ ■ ■ □ □          ■ ■ ■ ■ □ □
■ □ □ □ ■ □          ■ □ □ □ ■ □
■ □ □ □ ■ □          ■ □ □ □ ■ □
■ ■ ■ ■ □ □          ■ □ □ □ ■ □
■ □ □ □ □ □          ■ □ □ □ ■ □
■ □ □ □ □ □          ■ ■ ■ ■ □ □
```

## Сборка и запуск

### Требования

- Компилятор C++ с поддержкой C++17 (g++ 8+, clang++ 7+)
- Стандартная библиотека C++ (filesystem)

### Компиляция

```bash
cd Lab2
g++ -std=c++17 solution.cpp -o solution
```

### Запуск

```bash
./solution
```

## Структура файлов

```
Lab2/
├── README.md           # Этот файл
├── description.md      # Подробное описание задания
├── solution.cpp        # Исходный код решения
├── solution            # Скомпилированная программа
├── report.tex          # Отчет в формате LaTeX
├── report.pdf          # Скомпилированный отчет
└── patterns/           # Эталонные образы
    ├── N.txt           # Буква N
    ├── F.txt           # Буква F
    ├── I.txt           # Буква I
    ├── P.txt           # Буква P
    └── D.txt           # Буква D
```

## Пример вывода программы

```
========================================================
    ЛАБОРАТОРНАЯ РАБОТА №2: МНОГОСЛОЙНЫЙ ПЕРСЕПТРОН
    Вариант 2: буквы N, F, I, P, D
========================================================

1. Загрузка эталонных образов из patterns/...
   Загружено 5 паттернов

2. Создание обучающей выборки...
   Создано 5 обучающих примеров

3. Обучение многослойного персептрона...
   Обучение завершено за 6555 эпох

4. Тестирование на идеальных образах:
======================================

Класс 1 (N):
┌─────────────────────────────────┐
│ Распознаваемый образ (6×6):    │
│   ■ □ □ □ □ ■                  │
│   ■ ■ □ □ □ ■                  │
│   ■ □ ■ □ □ ■                  │
│   ■ □ □ ■ □ ■                  │
│   ■ □ □ □ ■ ■                  │
├─────────────────────────────────┤
│ Процент подобия:               │
│   Класс 1 (N):  99.2%  ◄── Распознан
│   Класс 2 (F):   0.3%
│   Класс 3 (I):   0.5%
│   Класс 4 (P):   0.4%
│   Класс 5 (D):   0.4%
└─────────────────────────────────┘
```

## Параметры сети

| Параметр | Значение |
|----------|----------|
| Входной слой | 36 нейронов |
| Скрытый слой | 20 нейронов |
| Выходной слой | 5 нейронов |
| Скорость обучения α | 0.5 |
| Скорость обучения β | 0.5 |
| Максимальная ошибка | 0.01 |

## Результаты

- **Идеальные образы:** 100% распознавание с уверенностью ~99%
- **Шум 10-20%:** Высокая точность распознавания
- **Шум 30-40%:** Умеренная точность
- **Шум 50%+:** Значительное снижение качества

## Сравнение с сетью Хопфилда

| Характеристика | Сеть Хопфилда | MLP |
|----------------|---------------|-----|
| Топология | Однослойная, с обратными связями | Многослойная, без обратных связей |
| Обучение | Без учителя (правило Хебба) | С учителем (backpropagation) |
| Функция активации | Пороговая | Сигмоидная |
| Выход | Восстановленный образ | Вероятности классов |
| Ёмкость | Ограничена | Практически неограничена |

## Выводы

1. Многослойный персептрон эффективно классифицирует образы
2. Алгоритм обратного распространения ошибки обеспечивает высокую точность
3. Процент подобия предоставляет информацию об уверенности классификации
4. Требует больше времени на обучение, чем сеть Хопфилда

## Компиляция отчета

```bash
cd Lab2
xelatex report.tex
```

Требуется XeLaTeX и шрифты DejaVu.

