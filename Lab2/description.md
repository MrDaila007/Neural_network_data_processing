# Лабораторная работа №2
## Многослойный персептрон

### 1. Цель работы

Изучение топологии, алгоритма функционирования многослойного персептрона.

### 2. Теоретические сведения

Многослойный персептрон является сетью с прямым распространением сигнала (без обратных связей), обучаемой с учителем. Такая сеть способна аппроксимировать любую непрерывную функцию или границу между классами со сколь угодно высокой точностью. Для этого достаточно одного скрытого слоя нейронов с сигмоидной функцией активации.

Многослойный персептрон обычно состоит из 3 слоев:
- Первого распределительного слоя (n входов)
- Второго скрытого слоя (h нейронов)
- Третьего выходного слоя (m выходных нейронов)

Используются две матрицы весов:
- Скрытого слоя `v` размером n×h
- Выходного слоя `w` размером h×m

С каждым слоем нейронов связан массив порогов:
- `Q` – для скрытого слоя
- `T` – для выходного

#### Функционирование персептрона

Персептрон функционирует по следующим формулам:

```
g_j = f(∑ v_ij * x_i + Q_j)
      i=1

y_k = f(∑ w_jk * g_j + T_k)
      j=1
```

В качестве функции активации используется сигмоидная функция:

```
f(x) = 1 / (1 + e^(-x))
```

#### Обучение

Обучение персептрона проводится с помощью алгоритма обратного распространения ошибки, который минимизирует среднеквадратичную ошибку нейронной сети.

**Алгоритм обратного распространения ошибки:**

1. **Инициализация**: Присвоить всем весам и порогам случайные значения из диапазона [-1,1].

2. **Для каждой пары векторов (x^r, y^r):**
   - Рассчитываются выходы нейронов скрытого слоя и выходы сети
   - Происходит коррекция знаний сети

3. **Коррекция весов:**

Для выходного слоя:
```
w_jk(t+1) = w_jk(t) + α * y_k * (1 - y_k) * d_k * g_j
T_k(t+1) = T_k(t) + α * y_k * (1 - y_k) * d_k
```

Для скрытого слоя:
```
v_ij(t+1) = v_ij(t) + β * g_j * (1 - g_j) * e_j * x_i
Q_j(t+1) = Q_j(t) + β * g_j * (1 - g_j) * e_j
```

где:
- `d_k = y_k^r - y_k` – ошибка k-го нейрона выходного слоя
- `e_j = ∑ d_k * f'(S_k) * w_jk` – ошибка j-го нейрона скрытого слоя
- `α`, `β` – скорости обучения

**Среднеквадратичная ошибка сети:**

```
E = (1/2) * ∑ (y_k^r - y_k)^2
    k=1
```

**Условие прекращения обучения:**

```
max |d_k| < D, k = 1, m, r = 1, p
```

где `D` – достаточно маленькая константа.

#### Оптимальное соотношение параметров

```
h ~ p / n
```

где:
- `h` – количество нейронов скрытого слоя
- `p` – количество примеров в обучающей выборке
- `n` – количество входов

### 3. Задание

1. Ознакомьтесь с теоретической частью.
2. На языке С, С++ напишите программу, реализующую многослойный персептрон.
3. Произведите обучение многослойного персептрона. Исходные данные - 5 классов образов, размер идеального образа 6×6 (в соответствии с вариантом).
4. Подайте на вход сети ряд тестовых образов, по 3 зашумленных образа каждого из 5 классов.
5. Проанализируйте результаты работы программы, которые должны иметь следующий вид:
   - вывести распознаваемый зашумленный образ
   - вывести процент подобия распознаваемого зашумленного образа по отношению к каждому из 5 классов
   - вывести количество шагов, затраченных на обучение сети на заданное количество классов
6. Напишите отчет.

#### Содержание отчета:

- топология многослойного персептрона;
- основные формулы обучения и воспроизведения;
- идеальные образы для обучения многослойного персептрона;
- тестовые зашумленные образы;
- результаты воспроизведения: процент подобия по отношению к каждому из классов, количество шагов, затраченных на обучение;
- результаты сравнения многослойного персептрона с нейронной сетью Хопфилда;
- выводы: преимущества и недостатки многослойного персептрона.

#### Варианты задания

| № варианта | 1-ый класс | 2-ой класс | 3-ий класс | 4-ый класс | 5-ый класс |
|------------|------------|------------|------------|------------|------------|
| 1          | 2          | 3          | 4          | 5          | 7          |
| 2          | N          | F          | I          | P          | D          |
| 3          | ∧          | ∨          | ∃          | ⊂          | ⊃          |
| 4          | ×          | ÷          | ×          | ÷          | ±          |
| 5          | ≤          | ≥          | ≠          | ≈          | ≅          |
| 6          | L          | U          | T          | O          | K          |
| 7          | →          | ←          | ↔          | ⇔          | ⇐          |

### 4. Контрольные вопросы

1. Топология многослойного персептрона.
2. Процесс обучения.
3. Процесс воспроизведения.
4. Процедура обратного распространения ошибки.
5. Каким образом можно улучшить качество распознавания?
6. Достоинства и недостатки данного типа нейронной сети.
