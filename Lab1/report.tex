\documentclass[12pt,a4paper]{article}
\usepackage{fontspec}
\usepackage{polyglossia}
\setdefaultlanguage{russian}
\setotherlanguage{english}
\setmainfont{DejaVu Serif}
\setsansfont{DejaVu Sans}
\setmonofont{DejaVu Sans Mono}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\geometry{margin=2.5cm}

% Настройка листингов для C++
\lstdefinestyle{cppstyle}{
    language=C++,
    basicstyle=\footnotesize\ttfamily,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black}\itshape,
    stringstyle=\color{red!70!black},
    numberstyle=\tiny\color{gray},
    numbers=left,
    numbersep=5pt,
    frame=single,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=4,
    showstringspaces=false,
    captionpos=b
}
\lstset{style=cppstyle}

\title{
    \textbf{Лабораторная работа №1}\\[0.5cm]
    \Large Нейронная сеть Хопфилда\\[0.3cm]
    \normalsize Вариант 5: буквы Д, Н, Х
}
\author{Елисеев Данила, 2025, ИС}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Цель работы}

Изучение топологии и алгоритма функционирования нейронной сети Хопфилда. Реализация программы для распознавания зашумленных образов русских букв.

\textbf{Задачи:}
\begin{enumerate}
    \item Реализовать нейронную сеть Хопфилда на языке C++
    \item Обучить сеть на 3 образах букв (Д, Н, Х) размером 10×10
    \item Исследовать устойчивость распознавания при различных уровнях шума
    \item Сравнить синхронный и асинхронный режимы работы сети
\end{enumerate}

\section{Теоретическая часть}

\subsection{Общие сведения о сети Хопфилда}

Сеть Хопфилда — это однослойная, симметричная, нелинейная, автоассоциативная нейронная сеть, которая запоминает бинарные или биполярные образы. Сеть характеризуется наличием обратных связей: информация с выхода каждого нейрона поступает на вход всех остальных нейронов.

\subsection{Топология сети}

Для данной работы используется сеть из \( n = 100 \) нейронов (для образов размером 10×10). Образы кодируются биполярным вектором: \( a_i \in \{-1, 1\} \).

Каждый нейрон связан со всеми остальными нейронами (полносвязная сеть), кроме самого себя (\( w_{ii} = 0 \)).

\subsection{Обучение сети}

Обучение сети осуществляется по правилу Хебба:

\[
w_{ij} = \begin{cases}
    \sum_{k=1}^{m} a_i^k \cdot a_j^k, & i \neq j \\
    0, & i = j
\end{cases}
\]

где:
\begin{itemize}
    \item \( w_{ij} \) — вес связи от \( i \)-го нейрона к \( j \)-му
    \item \( m \) — количество образов для обучения
    \item \( a_i^k \) — \( i \)-й элемент \( k \)-го образа
\end{itemize}

Матрица весовых коэффициентов \( W \) является \textbf{симметричной} (\( w_{ij} = w_{ji} \)) с \textbf{нулевой главной диагональю} (\( w_{ii} = 0 \)).

\subsection{Воспроизведение}

Для воспроизведения используется формула:

\[
a_i(t+1) = f\left(\sum_{j=1}^{n} w_{ij} \cdot a_j(t)\right)
\]

где \( f \) — биполярная пороговая функция активации:

\[
f(x) = \begin{cases} 1, & x \geq 0 \\ -1, & x < 0 \end{cases}
\]

\subsection{Режимы работы}

\textbf{Синхронный режим:} все нейроны одновременно обновляют свои состояния.

\textbf{Асинхронный режим:} на каждом шаге обновляется только один случайно выбранный нейрон.

\subsection{Ёмкость сети}

Максимальное количество образов:
\[
m \approx \frac{n}{2 \ln n + \ln \ln n}
\]

Для \( n = 100 \): \( m \approx 9 \) образов.

\section{Описание алгоритма}

\subsection{Алгоритм обучения}

\begin{enumerate}
    \item Инициализировать матрицу весов \( W \) нулями
    \item Для каждой пары \( (i, j) \), где \( i \neq j \): вычислить \( w_{ij} = \sum_{k=1}^{m} a_i^k \cdot a_j^k \)
    \item Диагональные элементы: \( w_{ii} = 0 \)
\end{enumerate}

\subsection{Алгоритм воспроизведения}

\begin{enumerate}
    \item Подать на вход зашумленный образ \( a(0) \)
    \item Повторять до стабилизации:
    \begin{itemize}
        \item Вычислить: \( sum_i = \sum_{j=1}^{n} w_{ij} \cdot a_j(t) \)
        \item Обновить: \( a_i(t+1) = sign(sum_i) \)
    \end{itemize}
    \item Если \( a(t+1) = a(t) \) — сеть стабилизировалась
\end{enumerate}

\section{Реализация}

\subsection{Структура проекта}

\begin{itemize}
    \item \texttt{solution.cpp} — основная программа на C++
    \item \texttt{patterns/} — эталонные образы (D.txt, N.txt, X.txt)
    \item \texttt{tests/} — тестовые образы (360 файлов)
    \item \texttt{tests/results.csv} — результаты тестирования
\end{itemize}

\subsection{Эталонные образы}

Буквы Д, Н, Х представлены в виде матриц 10×10:

{\small
\begin{verbatim}
Буква Д (10×10):         Буква Н (10×10):         Буква Х (10×10):
□ □ ■ ■ ■ ■ ■ ■ □ □     ■ □ □ □ □ □ □ □ □ ■     ■ □ □ □ □ □ □ □ □ ■
□ □ ■ □ □ □ □ ■ □ □     ■ □ □ □ □ □ □ □ □ ■     □ ■ □ □ □ □ □ □ ■ □
□ □ ■ □ □ □ □ ■ □ □     ■ □ □ □ □ □ □ □ □ ■     □ □ ■ □ □ □ □ ■ □ □
□ □ ■ □ □ □ □ ■ □ □     ■ □ □ □ □ □ □ □ □ ■     □ □ □ ■ □ □ ■ □ □ □
□ □ ■ □ □ □ □ ■ □ □     ■ ■ ■ ■ ■ ■ ■ ■ ■ ■     □ □ □ □ ■ ■ □ □ □ □
□ □ ■ □ □ □ □ ■ □ □     ■ ■ ■ ■ ■ ■ ■ ■ ■ ■     □ □ □ □ ■ ■ □ □ □ □
□ ■ ■ □ □ □ □ ■ ■ □     ■ □ □ □ □ □ □ □ □ ■     □ □ □ ■ □ □ ■ □ □ □
■ ■ ■ ■ ■ ■ ■ ■ ■ ■     ■ □ □ □ □ □ □ □ □ ■     □ □ ■ □ □ □ □ ■ □ □
■ □ □ □ □ □ □ □ □ ■     ■ □ □ □ □ □ □ □ □ ■     □ ■ □ □ □ □ □ □ ■ □
■ □ □ □ □ □ □ □ □ ■     ■ □ □ □ □ □ □ □ □ ■     ■ □ □ □ □ □ □ □ □ ■
\end{verbatim}
}

\subsection{Ключевые фрагменты кода}

\subsubsection{Обучение сети по правилу Хебба}

\begin{lstlisting}[caption={Функция обучения сети Хопфилда}]
void train() {
    // Инициализация весов нулями
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            weights[i][j] = 0;
        }
    }
    
    // Обучение по правилу Хебба
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            if (i != j) {
                for (int k = 0; k < NUM_PATTERNS; k++) {
                    weights[i][j] += patterns[k][i] * patterns[k][j];
                }
            }
        }
    }
}
\end{lstlisting}

\subsubsection{Синхронное воспроизведение}

\begin{lstlisting}[caption={Функция синхронного воспроизведения}]
Pattern recallSync(const Pattern& input, int& iterations) {
    Pattern current = input;
    Pattern next;
    iterations = 0;
    
    for (int iter = 0; iter < MAX_ITERATIONS; iter++) {
        iterations++;
        
        for (int i = 0; i < N; i++) {
            int sum = 0;
            for (int j = 0; j < N; j++) {
                sum += weights[i][j] * current[j];
            }
            next[i] = (sum >= 0) ? 1 : -1;
        }
        
        if (next == current) break;  // Стабилизация
        current = next;
    }
    
    return current;
}
\end{lstlisting}

\section{Результаты экспериментов}

\subsection{Методика тестирования}

Для каждой буквы и каждого уровня шума (10\%, 20\%, ..., 100\%) было сгенерировано по 10 тестовых образов. Всего: \( 3 \times 12 \times 10 = 360 \) тестов.

\subsection{Результаты для буквы Д}

\begin{table}[H]
\centering
\caption{Результаты распознавания буквы Д}
\begin{tabular}{|c|c|c|c|c|}
\hline
Шум & Sync успех & Sync итер. & Async успех & Async итер. \\
\hline
10\% & 10/10 & 2.0 & 10/10 & 200 \\
20\% & 10/10 & 2.0 & 10/10 & 200 \\
30\% & 10/10 & 2.0 & 10/10 & 200 \\
35\% & 10/10 & 2.2 & 10/10 & 220 \\
40\% & 6/10 & 2.2 & 7/10 & 230 \\
45\% & 5/10 & 2.8 & 5/10 & 250 \\
50\% & 4/10 & 2.3 & 4/10 & 200 \\
60\% & 1/10 & 2.3 & 2/10 & 220 \\
70\%+ & 0/10 & 2.0 & 0/10 & 200 \\
\hline
\end{tabular}
\end{table}

\subsection{Результаты для буквы Н}

\begin{table}[H]
\centering
\caption{Результаты распознавания буквы Н}
\begin{tabular}{|c|c|c|c|c|}
\hline
Шум & Sync успех & Sync итер. & Async успех & Async итер. \\
\hline
10\% & 10/10 & 2.0 & 10/10 & 200 \\
20\% & 10/10 & 2.0 & 10/10 & 200 \\
30\% & 10/10 & 2.0 & 10/10 & 200 \\
35\% & 10/10 & 2.0 & 10/10 & 200 \\
40\% & 7/10 & 2.3 & 7/10 & 200 \\
45\% & 5/10 & 2.5 & 6/10 & 220 \\
50\% & 1/10 & 102 & 3/10 & 210 \\
60\%+ & 0/10 & 2.2 & 0/10 & 210 \\
\hline
\end{tabular}
\end{table}

\subsection{Результаты для буквы Х}

\begin{table}[H]
\centering
\caption{Результаты распознавания буквы Х}
\begin{tabular}{|c|c|c|c|c|}
\hline
Шум & Sync успех & Sync итер. & Async успех & Async итер. \\
\hline
10\% & 10/10 & 2.0 & 10/10 & 200 \\
20\% & 10/10 & 2.0 & 10/10 & 200 \\
30\% & 10/10 & 2.0 & 10/10 & 200 \\
35\% & 10/10 & 2.1 & 10/10 & 200 \\
40\% & 8/10 & 2.2 & 7/10 & 200 \\
45\% & 5/10 & 2.8 & 5/10 & 220 \\
50\% & 0/10 & 302 & 1/10 & 200 \\
60\%+ & 0/10 & 2.3 & 0/10 & 210 \\
\hline
\end{tabular}
\end{table}

\subsection{Сводная статистика}

\begin{table}[H]
\centering
\caption{Сводная статистика по уровням шума}
\begin{tabular}{|c|c|c|}
\hline
Шум & Синхронный & Асинхронный \\
\hline
10\% & 100\% & 100\% \\
20\% & 100\% & 100\% \\
30\% & 100\% & 100\% \\
35\% & 100\% & 100\% \\
40\% & 70\% & 70\% \\
45\% & 50\% & 53\% \\
50\% & 17\% & 27\% \\
60\% & 3\% & 7\% \\
70\%+ & 0\% & 0\% \\
\hline
\end{tabular}
\end{table}

\section{Выводы}

\begin{enumerate}
    \item \textbf{Успешная реализация:} Нейронная сеть Хопфилда реализована и обучена на 3 образах букв (Д, Н, Х) размером 10×10.
    
    \item \textbf{Устойчивость к шуму:} При уровне шума до 35\% — 100\% успешное распознавание.
    
    \item \textbf{Критический порог:} При 40–50\% шума качество падает до 17–70\%.
    
    \item \textbf{Потеря информации:} При шуме выше 60\% распознавание невозможно.
    
    \item \textbf{Сравнение режимов:} Синхронный быстрее (2–3 итерации), асинхронный немного лучше при высоком шуме.
    
    \item \textbf{Рекомендации:} Использовать сеть при шуме до 30–35\%.
\end{enumerate}

\end{document}
