\documentclass[12pt,a4paper]{article}
\usepackage{fontspec}
\usepackage{polyglossia}
\setdefaultlanguage{russian}
\setotherlanguage{english}
\setmainfont{DejaVu Serif}
\setsansfont{DejaVu Sans}
\setmonofont{DejaVu Sans Mono}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{geometry}

\geometry{left=2.5cm,right=2.5cm,top=2cm,bottom=2cm}

\title{
    \textbf{Лабораторная работа №3}\\[0.5cm]
    \Large Сеть РБФ (Радиальная Базисная Функция)\\[0.3cm]
    \normalsize Вариант 2: классы N, F, I, P, D
}
\author{Елисеев Данила, 2025, ИС}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Цель работы}

Изучение топологии и алгоритма функционирования сети РБФ (радиальная базисная функция). Реализация программы для распознавания зашумленных образов.

\textbf{Задачи:}
\begin{enumerate}
    \item Реализовать сеть РБФ на языке C++
    \item Обучить сеть на 5 классах образов (N, F, I, P, D) размером 6×6
    \item Исследовать способность сети распознавать зашумленные образы
    \item Проанализировать процент подобия распознаваемых образов к каждому классу
\end{enumerate}

\section{Теоретическая часть}

\subsection{Общие сведения о сети РБФ}

Сеть РБФ (радиальная базисная функция) является аналогом многослойного персептрона. Скорость обучения такой сети гораздо выше, причем допускается полностью аналитический подход к расчету весовых коэффициентов. Однако эти положительные моменты сопровождаются рядом недостатков, главным из которых является ухудшение точности аппроксимации.

\subsection{Топология сети}

Сеть РБФ состоит из трех слоев:
\begin{itemize}
    \item \textbf{Входной слой} (распределительный) — передает входные данные на РБФ слой
    \item \textbf{РБФ слой} (скрытый) — содержит РБФ ячейки, каждая из которых вычисляет гауссову функцию
    \item \textbf{Выходной слой} (суммирующий) — линейная комбинация выходов РБФ ячеек
\end{itemize}

Для данной работы используется сеть с \( n = 36 \) входами (образы размером 6×6), \( h = 5 \) РБФ ячейками (по одной на класс) и \( m = 5 \) выходными нейронами (по одному на класс).

\subsection{Функция РБФ ячейки}

Классический закон, по которому РБФ ячейка функционирует, определяется формулой \textbf{гауссового колокола}:

\[
g_j = \exp\left(-\frac{\|x - t_j\|^2}{\sigma_j^2}\right)
\]

где:
\begin{itemize}
    \item \( x \) — входной вектор
    \item \( t_j \) — вектор, определяющий математическое ожидание (центр кластера) РБФ ячейки
    \item \( \sigma_j \) — среднеквадратическое отклонение (параметр разброса)
\end{itemize}

\textbf{Евклидово расстояние} между векторами \( x \) и \( t_j \) вычисляется как:

\[
\|x - t_j\|^2 = \sum_{i=1}^{n} (x_i - t_{ij})^2
\]

\subsection{Обучение РБФ ячеек}

\textbf{Выбор центров:}
\begin{itemize}
    \item В качестве центра выбирается центр кластера в пространстве признаков
    \item В простейшем случае, если класс задается одним идеальным образом, этот образ и будет являться вектором \( t_j \)
\end{itemize}

\textbf{Выбор параметра разброса \( \sigma_j \):}
\begin{itemize}
    \item Выбирается как половина расстояния до ближайшего центра ячейки, соответствующей другому классу
    \item \( \sigma_j = d_{jk} / 2 \), где \( d_{jk} \) — расстояние до ближайшего центра другого класса
\end{itemize}

\subsection{Выходной слой}

Выходной слой РБФ сети состоит из суммирующих ячеек:

\[
y_k = \sum_{j=1}^{h} w_{jk} \times g_j
\]

где \( w_{jk} \) — вес связи от \( j \)-й РБФ ячейки к \( k \)-му выходному нейрону.

\subsection{Обучение выходного слоя}

Обучение выходного слоя производится по алгоритму градиентного спуска:

\[
w_{jk} := w_{jk} + \alpha \times d_k \times g_j
\]

где:
\begin{itemize}
    \item \( d_k = y_k^r - y_k \) — ошибка \( k \)-го нейрона
    \item \( \alpha \) — скорость обучения
    \item \( y_k^r \) — желаемый выход
\end{itemize}

Поскольку функция активации в выходном слое сети РБФ \textbf{линейная} и ее производная равна 1, формула упрощается по сравнению с многослойным персептроном.

\subsection{Воспроизведение}

Сеть функционирует по формулам:

\textbf{РБФ слой:}
\[
g_j = \exp\left(-\frac{\|x - t_j\|^2}{\sigma_j^2}\right)
\]

\textbf{Выходной слой:}
\[
y_k = \sum_{j=1}^{h} w_{jk} \times g_j
\]

\section{Описание алгоритма}

\subsection{Алгоритм инициализации РБФ ячеек}

\begin{enumerate}
    \item Для каждого класса \( i = 1, \ldots, m \):
    \begin{itemize}
        \item Установить центр РБФ ячейки: \( t_i = \) идеальный образ класса \( i \)
    \end{itemize}
    \item Для каждой РБФ ячейки \( j = 1, \ldots, h \):
    \begin{itemize}
        \item Найти минимальное расстояние до центра другого класса: \( d_{min} = \min_{k \neq j} \|t_j - t_k\| \)
        \item Установить параметр разброса: \( \sigma_j = d_{min} / 2 \)
    \end{itemize}
\end{enumerate}

\subsection{Алгоритм обучения выходного слоя}

\begin{enumerate}
    \item Инициализировать веса \( w_{jk} \) случайными малыми значениями
    \item Повторять до сходимости или достижения максимального числа итераций:
    \begin{itemize}
        \item Для каждого обучающего образа \( x^k \) класса \( k \):
        \begin{itemize}
            \item Вычислить выходы РБФ слоя: \( g_j = \exp\left(-\frac{\|x^k - t_j\|^2}{\sigma_j^2}\right) \)
            \item Вычислить выходы выходного слоя: \( y_l = \sum_{j=1}^{h} w_{jl} \times g_j \)
            \item Вычислить ошибку: \( d_l = y_l^r - y_l \), где \( y_l^r = 1 \) если \( l = k \), иначе \( 0 \)
            \item Скорректировать веса: \( w_{jl} := w_{jl} + \alpha \times d_l \times g_j \)
        \end{itemize}
    \end{itemize}
\end{enumerate}

\subsection{Алгоритм распознавания}

\begin{enumerate}
    \item Подать на вход зашумленный образ \( x \)
    \item Вычислить выходы РБФ слоя: \( g_j = \exp\left(-\frac{\|x - t_j\|^2}{\sigma_j^2}\right) \)
    \item Вычислить выходы выходного слоя: \( y_k = \sum_{j=1}^{h} w_{jk} \times g_j \)
    \item Нормализовать выходы в проценты: \( p_k = \frac{y_k}{\sum_{l=1}^{m} y_l} \times 100\% \)
    \item Класс с максимальным процентом является результатом распознавания
\end{enumerate}

\section{Реализация}

\subsection{Структура проекта}

\begin{itemize}
    \item \texttt{solution.cpp} — основная программа на C++
    \item \texttt{patterns/} — эталонные образы (N.txt, F.txt, I.txt, P.txt, D.txt)
    \item \texttt{tests/} — тестовые зашумленные образы
\end{itemize}

\subsection{Идеальные образы для обучения}

Образы классов N, F, I, P, D представлены в виде матриц 6×6:

\begin{verbatim}
Класс N (6x6):      Класс F (6x6):      Класс I (6x6):
■ □ □ □ □ ■        ■ ■ ■ ■ ■ ■        ■ ■ ■ ■ ■ ■
■ ■ □ □ □ ■        ■ □ □ □ □ □        □ □ ■ ■ □ □
■ □ ■ □ □ ■        ■ □ □ □ □ □        □ □ ■ ■ □ □
■ □ □ ■ □ ■        ■ ■ ■ ■ □ □        □ □ ■ ■ □ □
■ □ □ □ ■ ■        ■ □ □ □ □ □        □ □ ■ ■ □ □
■ □ □ □ □ ■        ■ □ □ □ □ □        ■ ■ ■ ■ ■ ■

Класс P (6x6):      Класс D (6x6):
■ ■ ■ ■ □ □        ■ ■ ■ ■ □ □
■ □ □ □ ■ □        ■ □ □ □ ■ □
■ □ □ □ ■ □        ■ □ □ □ ■ □
■ ■ ■ ■ □ □        ■ □ □ □ ■ □
■ □ □ □ □ □        ■ □ □ □ ■ □
■ □ □ □ □ □        ■ ■ ■ ■ □ □
\end{verbatim}

\section{Результаты экспериментов}

\subsection{Методика тестирования}

Для каждого класса и каждого уровня шума (10\%, 20\%, 30\%, 40\%, 50\%) было сгенерировано по 3 тестовых образа. Всего: \( 5 \times 5 \times 3 = 75 \) тестов.

\subsection{Примеры результатов распознавания}

Для каждого тестового образа программа выводит:
\begin{itemize}
    \item Распознаваемый зашумленный образ (6×6)
    \item Процент подобия по отношению к каждому из 5 классов
    \item Количество шагов, затраченных на обучение сети
\end{itemize}

\textbf{Пример вывода:}

\begin{verbatim}
┌─────────────────────────────────────────────────┐
│ Распознаваемый образ (6×6):                     │
│                                                 │
│   ■ □ □ □ □ ■                                   │
│   ■ ■ □ □ □ ■                                   │
│   ■ □ ■ □ □ ■                                   │
│   ■ □ □ ■ □ ■                                   │
│   ■ □ □ □ ■ ■                                   │
│   ■ □ □ □ □ ■                                   │
│                                                 │
├─────────────────────────────────────────────────┤
│ Процент подобия (выход РБФ):                    │
│   Класс 1 (N): 85.2%  ◄── Распознан как "N"     │
│   Класс 2 (F): 3.1%                             │
│   Класс 3 (I): 5.4%                             │
│   Класс 4 (P): 4.8%                             │
│   Класс 5 (D): 1.5%                             │
│                                                 │
├─────────────────────────────────────────────────┤
│ Шагов обучения: 87                              │
└─────────────────────────────────────────────────┘
\end{verbatim}

\subsection{Анализ результатов}

Сеть РБФ успешно распознает зашумленные образы, показывая процент подобия для каждого класса. Класс с максимальным процентом подобия является результатом распознавания.

\section{Сравнение с многослойным персептроном}

\begin{center}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Характеристика} & \textbf{Многослойный персептрон} & \textbf{Сеть РБФ} \\
\hline
Скорость обучения & Медленная & Быстрая \\
\hline
Количество слоев для обучения & 2 (скрытый + выходной) & 1 (только выходной) \\
\hline
Точность аппроксимации & Высокая & Ограниченная \\
\hline
Универсальность & Широкий класс задач & Хорошо кластеризуемые классы \\
\hline
Подбор параметров & Веса, пороги, скорость обучения & Центры, \( \sigma \), веса выходного слоя \\
\hline
\end{tabular}
\end{center}

\section{Выводы}

\begin{enumerate}
    \item \textbf{Успешная реализация:} Сеть РБФ реализована и обучена на 5 классах образов (N, F, I, P, D) размером 6×6.
    
    \item \textbf{Быстрое обучение:} Обучение выходного слоя завершается за относительно небольшое количество шагов (обычно менее 100 итераций), что значительно быстрее многослойного персептрона.
    
    \item \textbf{Распознавание зашумленных образов:} Сеть способна распознавать зашумленные образы, показывая процент подобия для каждого класса.
    
    \item \textbf{Процент подобия:} Выход сети показывает степень соответствия входного образа каждому классу, что позволяет оценить уверенность распознавания.
    
    \item \textbf{Преимущества:}
    \begin{itemize}
        \item Высокая скорость обучения (обучается только выходной слой)
        \item Простота реализации
        \item Хорошая работа для хорошо кластеризуемых классов
    \end{itemize}
    
    \item \textbf{Недостатки:}
    \begin{itemize}
        \item Ограниченная точность аппроксимации по сравнению с многослойным персептроном
        \item Требуется правильный выбор центров и параметров разброса
        \item Хорошо работает только для ограниченного класса аппроксимируемых функций
    \end{itemize}
    
    \item \textbf{Рекомендации:} Сеть РБФ целесообразно использовать в задачах классификации с хорошо кластеризуемыми классами, где важна скорость обучения.
\end{enumerate}

\end{document}
