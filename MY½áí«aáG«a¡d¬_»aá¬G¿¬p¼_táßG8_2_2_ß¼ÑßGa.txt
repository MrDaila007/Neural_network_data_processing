                          Содержание


Общие теоретические сведения………………………………………….4
1. Лабораторная работа №1. Нейронная сеть Хопфилда…………….10
2. Лабораторная работа №2. Многослойный персептрон……………15
3. Лабораторная работа №3. Сеть РБФ………………………………..23
4. Лабораторная работа №4. Конкурентная нейронная сеть………...27
Литература……………………………………………………………….31




                                                                 1
                            НЕЙРОННЫЕ СЕТИ

                   Общие теоретические сведения
    Приведем одно из определений искусственных нейронных сетей [1]:
    Искусственная нейронная сеть (ИНС) – это существенно параллельно
распределенный процессор, который обладает способностью к сохранению и
репрезентации опытного знания. Она сходна с мозгом в двух аспектах:
    знание приобретается сетью в процессе обучения;
    для сохранения знания используются силы межнейронных соединений,
      называемые также синаптическими соединениями.
      Работа нейронной сети (НС) состоит в преобразовании входных сигналов
во времени, в результате чего меняется внутреннее состояние сети и формиру-
ются выходные воздействия. Обычно НС оперирует цифровыми, а не символь-
ными величинами. Большинство моделей НС требуют обучения. В общем слу-
чае, обучение — это такой выбор параметров сети, при котором сеть лучше
всего справляется с поставленной проблемой. Обучение — это задача много-
мерной оптимизации и для ее решения существует множество алгоритмов.
      Современные искусственные НС демонстрируют такие ценные свойства,
как:
      1. Обучаемость. Выбрав одну из моделей НС, создав сеть и выполнив ал-
горитм обучения, мы можем обучить сеть решению задачи, которая ей по си-
лам.
      2. Способность к обобщению. После обучения сеть становится нечув-
ствительной к малым изменениям входных сигналов (шуму или вариациям
входных образов) и дает правильный результат на выходе.
      3. Способность к абстрагированию. Если предъявить сети несколько ис-
каженных вариантов входного образа, то сеть сама может создать на выходе
идеальный образ, с которым она никогда не встречалась.
    К задачам, успешно решаемым НС на данном этапе их развития относятся:
     распознавание зрительных, слуховых образов;
     ассоциативный поиск информации и создание ассоциативных моделей,
       синтез речи, формирование естественного языка;
     формирование моделей и различных нелинейных и трудно описываемых
       математически систем, прогнозирование развития этих систем во време-
       ни;
     системы управления и регулирования с предсказанием;
     разнообразные конечные автоматы: системы массового обслуживания и
       коммутации, телекоммуникационные системы;
     принятие решений и диагностика, исключающие логический вывод, осо-
       бенно в областях, где отсутствуют четкие математические модели: в ме-
       дицине, криминалистике, финансовой сфере.


2
     На рис. 1.1 показана структура пары типичных биологических нейронов.
Дендриты идут от тела нервной клетки к другим нейронам, где они принимают
сигналы в точках соединения, называемых синапсами. Принятые синапсом
входные сигналы подводятся к телу нейрона. Здесь они суммируются, причем
одни входы стремятся возбудить нейрон, другие – воспрепятствовать его воз-
буждению. Когда суммарное возбуждение в теле нейрона превышает некото-
рый порог, нейрон возбуждается, посылая по аксону сигнал другим нейронам.
У этой основной функциональной схемы много усложнений и исключений, тем
не менее большинство искусственных нейронных сетей моделируют лишь эти
простые свойства.




                           Рис. 1.1. Биологический нейрон

     Основным элементом нейронной сети является нейрон, который осу-
ществляет операцию нелинейного преобразования суммы произведений вход-
ных сигналов на весовые коэффициенты:
              n
      y  f (  wi xi  T ),                                             (1.1)
             i 1

где X=(x1,x2,…,xn) – вектор входного сигнала; W=(w1,w2,…,wn) – весовой вектор;
T - порог; f – так называемая функция активации.
      Схема нейронного элемента изображена на рис 1.2. Каждому i-му входу
нейрона соответствует весовой коэффициент wi (синапс), который характеризу-
ет силу синаптической связи по аналогии с биологическим нейроном.




                                                                             3
                              x1       w1
                                            T
                                                      y
                                       w2
                              x2
                                       wn       f
                                   

                              xn
                               Рис. 1.2. Искусственный нейрон

      Весовой вектор W, порог T и пороговая функция f определяют поведение
любого нейрона – его реакцию на входные данные. Величина веса wi определя-
ет степень влияния входа i на выход нейрона, а знак – характер влияния. Каж-
дый из входов связан с некоторым источником информации (рецептор, форми-
рующий признаки, распределительная ячейка, выход другого нейрона). Поло-
жительные веса характерны для возбуждающих связей, способствующих по-
вышению активности нейрона. Отрицательные, как правило, соответствуют
тормозящим связям.
      Порог, если он используется, является характеристикой, задающей
начальный уровень активности (при нулевом входе) и помогающей настроить
нейрон на пороговую функцию. Изменение порога эквивалентно сдвигу поро-
говой функции по оси абсцисс. Ряд авторов [2] вводят дополнительный вход
нейрона x0, всегда равный 1, и обозначают порог как его вес w0. Это позволяет
упростить выражение (1.1) и математическую запись некоторых алгоритмов
обучения. Однако на практике при программной реализации это не приводит к
экономии времени и способствует ошибкам, кроме этого, порог может настра-
иваться иначе, чем весовой вектор.
      Функция активации используется для ограничения выхода нейрона в
заданном диапазоне и для нелинейного преобразования взвешенной суммы.
Последнее позволяет нейронному классификатору аппроксимировать любую
нелинейную границу между классами в пространстве образов. Функция акти-
вации выбирается для конкретной задачи и является неизменной характеристи-
кой отдельного нейрона.
      Могут использоваться следующие функции активации и их гибриды:
      1) линейная функция y=Ax;
                                1, x  0
      2) пороговая функция y             ;
                                0 , x  0
                                              1, x  0
      3) биполярная пороговая функция y                ;
                                              1, x  0
      4) сигмоидная функция (рис. 1.2)

                1
      y                  ;                                             (1.2)
           (1  e  x )


4
                                                     1


                              1
                         1 exp(  x)

                              2              5               0       5
                                        1
                         1 exp(  x)



                                                     1

                                                         x

                         Рис. 1.2. Сигмоидные функции активации

     5) биполярная сигмоидная функция (см. рис. 1.2)

               2
     y                   1;                                                (1.3)
          (1  e  x )

     6) гиперболический тангенс (рис. 1.3)

                    e x  e x
     y  th( x)                        .                                    (1.4)
                    e x  e x

                                                         1




                                  tanh( x)
                                                 5               0       5




                                                         1

                                                             x



                                  Рис. 1.3. Гиперболический тангенс

     Для классификаторов чаще всего применяют функции (1.2) – (1.4), по-
скольку они нелинейные и хорошо дифференцируются.
     Веса и порог конкретного нейрона являются настраиваемыми парамет-
рами. Они содержат знания нейрона, определяющие его поведение. Процесс
настройки этих знаний с целью получения нужного поведения называется обу-
чением.
     Нейронная сеть – совокупность нейронных элементов и связей между
ними. Слоем нейронной сети называется множество нейронных элементов, на
которые в каждый такт времени параллельно поступает информация от других
нейронных элементов сети. Помимо слоев нейронов часто используется поня-

                                                                                 5
тие входного распределительного слоя. Распределительный слой передает
входные сигналы на первый обрабатывающий слой нейронных элементов (рис.
1.4).


                       x1         wij
                             1

                       x2
                             2                    …
                             …




                                        …
                       xn
                             n
                     Рис. 1.4. Распределительный слой

       У любой нейронной сети можно выделить 2 режима работы: обучение и
воспроизведение. На этапе обучения настраиваются веса и пороги всех слоев.
Воспроизведение является этапом обработки информации, следующим за обу-
чением, при этом веса и пороги, как правило, не изменяются. Большое влияние
на функционирование сети оказывает ее топология – архитектура слоев и свя-
зей между нейронами.
       На способе обработки информации решающим образом сказывается
наличие или отсутствие в сети обратных связей. Если обратных связей нет
(каждый нейрон получает информацию только от нейронов предыдущих сло-
ев), то обработка информации происходит в одном направлении за число так-
тов, равное числу слоев. При наличии обратных связей информация может
проходить через сеть много раз до достижения какого-либо условия. В случае,
если условие достигнуто, говорят, что сеть стабилизировалась. В общем случае
сходимость не гарантируется. Тем не менее наличие обратных связей позволяет
решать задачи с привлечением меньшего числа нейронов, что ускоряет процесс
обучения.

     Для лучшего понимания данного вопроса приведем одну из возможных
классификаций НС в зависимости от различных характеристик [2]:
     1. По типу входной информации:
           аналоговые НС (используют информацию в форме действитель-
             ных чисел);
           двоичные НС (оперируют с информацией, представленной в
             двоичном виде);
     2. По характеру обучения:
           с учителем (известно входное пространство решений НС);



6
        без учителя (НС формирует выходное пространство решений
          только на основе входных воздействий – самоорганизующиеся
          сети);
3.   По характеру настройки синапсов:
        сети с фиксированными связями (весовые коэффициенты НС
          выбираются сразу, исходя из условия задачи);
        сети с динамическими связями (в процессе обучения происхо-
          дит настройка синаптических связей);
4.   По методу обучения
        НС с алгоритмом обратного распространения ошибки;
        НС с конкурентным обучением;
        НС, использующие правило Хебба;
        НС с гибридным обучением, в которых используются различные
          алгоритмы обучения;
5.   По характеру связей:
        НС с прямыми связями;
        НС с обратным распространением информации;
6.   По архитектуре и обучению:
        персептронные сети с прямыми связями;
        самоорганизующиеся НС (НС Кохонена, НС адаптивного резо-
          нанса, рециркуляционные НС);
        НС с обратными связями (НС Хопфилда, НС Хэмминга, двуна-
          правленная ассоциативная память, рекуррентные НС);
        гибридные НС (НС встречного распространения, НС с радиаль-
          но-базисной функцией активации).




                                                                  7
                      Лабораторная работа №1
                      Нейронная сеть Хопфилда
                                1. Цель работы

     Изучение топологии, алгоритма функционирования сети Хопфилда.

                          2. Теоретические сведения

     Сеть Хопфилда – однослойная, симметричная, нелинейная, автоассоциа-
тивная нейронная сеть, которая запоминает бинарные / биполярные образы.
Сеть характеризуется наличием обратных связей. Топология сети Хопфилда
показана на рис. 2.1. Информация с выхода каждого нейрона поступает на вход
всех остальных нейронов. Образы для данной модификации сети Хопфилда
кодируются биполярным вектором, состоящим из 1 и –1.


                                a1



                                a2

                                ...            ...

                                an


                      Рис. 2.1. Топология сети Хопфилда

     Обучение. Обучение сети осуществляется в соответствии с соотношени-
ем

            m k k
      wij    i j
             a a , i j
                         , для i, j  1, n ,                          (2.1)
              k 1
             0, i  j
            

где wij – вес связи от i-го нейрона к j-му;
       n – количество нейронов в сети;
       m – количество образов, используемых для обучения сети;
       aik – i-й элемент k-го образа из обучающей выборки.
       Матрица весовых коэффициентов




8
          w11   w12   w1n 
         w      w22  w2 n 
     W   21               .                                        (2.2)
                 
                           
          wn1   wn 2  wnn 

      В качестве матрицы весовых коэффициентов Хопфилд использовал сим-
метричную матрицу (wij=wji) с нулевой главной диагональю (wii=0). Последнее
условие соответствует отсутствию обратной связи нейронного элемента на се-
бя. В качестве функции активации нейронных элементов может использоваться
как пороговая, так и непрерывная функция, например сигмоидная или гипер-
болический тангенс.
      Будем рассматривать нейронную сеть Хопфилда с дискретным временем.
Тогда при использовании пороговой функции активации она называется
нейронной сетью с дискретным состоянием и временем. Нейронная сеть с не-
прерывной функцией активации называется нейронной сетью с непрерывным
состоянием и дискретным временем. При использовании непрерывного време-
ни модель Хопфилда называется непрерывной.
      Для описания функционирования таких сетей Хопфилд использовал ап-
парат статистической физики. При этом каждый нейрон имеет два состояния
активности (1, –1), которые аналогичны значениям спина некоторой частицы.
Весовой коэффициент wji можно интерпретировать как вклад поля j – частицы
в величину потенциала i – частицы. Хопфилд показал, что поведение такой се-
ти аналогично поведению лизингового спинового стекла. При этом он ввел по-
нятие вычислительной энергии, которую можно интерпретировать в виде
ландшафта с долинами и впадинами. Структура соединений сети определяет
очертания ландшафта. Нейронная сеть выполняет вычисления, следуя по пути,
уменьшающему вычислительную энергию сети. Это происходит до тех пор,
пока путь не приведет на дно впадины. Данный процесс аналогичен скатыва-
нию капли жидкости по склону, когда она минимизирует свою потенциальную
энергию в поле тяготения. Впадины и долины в сети Хопфилда соответствуют
наборам информации, которую хранит сеть. Если процесс начинается с при-
ближенной или неполной информации, то он следует по пути, который ведет к
ближайшей впадине. Это соответствует операции ассоциативного распознава-
ния.
      Матрица весов является диагонально симметричной, причем все диаго-
нальные элементы равны 0.
      Воспроизведение. Нейронная сеть Хопфилда может функционировать
синхронно и асинхронно. Для воспроизведения используется соотношение




                                                                          9
                      n             
      ai t  1  f   wij a j t  ,                                    (2.3)
                                    
                      j 1          

где aj(t) – выход j-го нейрона в момент времени t, а f – бинарная / биполярная
функция активации;

                1 x  0,
      f x                                                               (2.4)
                1 x  0 .

      При работе в синхронном режиме на один такт работы сети все нейроны
одновременно меняют состояние по формуле (2.4). В случае асинхронной ра-
боты состояние меняет только один случайный нейрон. Итерации продолжают-
ся до тех пор, пока сеть не придет в стабильное состояние.
      Во время воспроизведения исходным вектором a(0) является некоторый
тестовый образ, не совпадающий с образами из обучающей выборки. В процес-
се функционирования по формуле (2.4) сеть должна прийти в состояние, соот-
ветствующее образу из обучающей выборки, наиболее похожему на тестовый.
      Максимальное количество образов, которое можно запомнить в матрице
W не превышает

                  n
      m                    ,                                               (2.5)
           2 ln n  ln ln n

где n – количество нейронов, что следует отнести к недостаткам этой сети.


                                           3. Задание

      1. Ознакомьтесь с теоретической частью.
      2. На языке С, С++ напишите программу, реализующую нейронную сеть
Хопфилда.
      3. Произведите обучение сети Хопфилда на заданный тип образов. Для
запоминания в соответствии с вариантом задано 3 образа (бинарные изображе-
ния размером 1010).
      4. Подайте на вход сети ряд тестовых образов, в которые внесено зашум-
ление (процент зашумления образа – 10%, 20%, 30%, 35%, 40%, 45%, 50%,
60%, 70%, 80%, 90%, 100%). Тестовых образов должно быть не менее 10 для
каждого из классов с одним и тем же процентом зашумления.
      5. Проанализируйте результаты, при каком проценте зашумления тесто-
вые образы распознаются верно.
      6. Напишите отчет.


10
       Содержание отчета:
          топология сети Хопфилда;
          описание алгоритма работы сети;
          тестируемые образы (3 образа);
          искаженные образы (процент зашумления образа – 10%, 20%, 30%,
            35%, 40%, 45%, 50%, 60%, 70%, 80%, 90%, 100%);
          результаты распознавания, статистика;
          выводы.

                                                               Таблица 2.1
                              Варианты задания
   №                1-ый                    2-ой                3-ий
варианта      тестируемый образ      тестируемый образ   тестируемый образ
   1                «А»                    «И»                 «Р»
   2                «Б»                    «К»                 «С»
   3                «В»                    «Л»                 «Т»
   4                «Г»                    «М»                 «У»
   5                «Д»                    «Н»                 «Х»
   6                «Е»                    «О»                 «Ш»
   7                «З»                    «П»                 «Ь»


                           4. Контрольные вопросы

      1. Топология сети Хопфилда.
      2. Обучение сети Хопфилда.
      3. Процесс воспроизведения информации в сети Хопфилда.
      4. Зависимость максимального количества образов, запоминаемых сетью,
от ее размера.
      5. В чем причина некорректной работы при запоминании подобных обра-
зов?
      6. Варианты использования сети Хопфилда.




                                                                        11
                                                                    Таблица 2.2
            Пример задания тестируемого и искаженных образов
                     Процент                       Процент
     Тестируемый                Вид искаженно-                Вид искаженно-
                   зашумления                    зашумления
        образ                      го образа                     го образа
                      образа                        образа




                   10%                           50%




                   20%                           60%




                   30%                           70%




                   35%                           80%




                   40%                           90%




                   45%                           100%




12
                           Лабораторная работа №2
                           Многослойный персептрон
                                        1. Цель работы

     Изучение топологии, алгоритма функционирования многослойного пер-
септрона.

                                    2. Теоретические сведения

      Многослойный персептрон является сетью с прямым распространением
сигнала (без обратных связей), обучаемой с учителем. Такая сеть способна ап-
проксимировать любую непрерывную функцию или границу между классами
со сколь угодно высокой точностью. Для этого достаточно одного скрытого
слоя нейронов с сигмоидной функцией активации (1.2) – (1.4), т.е. многослой-
ный персептрон обычно состоит из 3 слоев: первого распределительного, вто-
рого скрытого и третьего выходного (рис. 3.1).

                                       vij         wjk
                      x1                                        y1
                              x1             g1          y1
                             …




                                             …




                                                         …


                      xi                                        yk
                               xi            gj          yk
                             …




                                             …




                                                         …




                      xn                                        yt
                              xn             gh          Ym

                                             Qj          Tk

                           Рис. 3.1. Многослойный персептрон

      Такая сеть имеет n входов и n нейронов распределительного слоя, h
нейронов скрытого слоя и m выходных нейронов. Используются две матрицы
весов: скрытого слоя v размером nh и выходного слоя w размером hm. Кроме
этого, с каждым слоем нейронов связан массив порогов: Q – для скрытого слоя,
T – для выходного. Эти данные представляют собой знания сети, настраивае-
мые в процессе обучения и определяющие ее поведение. Персептрон функцио-
нирует по следующим формулам:

                n
      g j  f (  vij xi  Q j ) ,                                     (3.1)
               i 1



                                                                          13
                  h
       y k  f (  w jk g j  Tk ) .                                                     (3.2)
                 j 1

         В качестве функции активации используется одна из функций (1.2) –
(1.4). Вид функции определяет диапазон чисел, в котором работает сеть. В
дальнейшем будет использоваться сигмоидная функция (1.2), имеющая область
значений от 0 до 1.
         Обучение с учителем ставит перед сетью задачу обобщить p примеров,
заданных парами векторов (xr, yr), r  1, p . Вектор x r  ( x1r , x2r ,...xir ,...xnr ) в слу-
чае задачи классификации задает входной образ (вектор признаков), а вектор
 y r  ( y1r , y 2r ,... y kr ,... y mr ) , задающий эталонный выход, должен кодировать номер
класса. При этом есть множество вариантов кодирования. Оптимальным пред-
ставляется кодирование, когда номер класса определяется позицией единичной
компоненты в векторе yr, а все остальные компоненты равны 0. Каждый вы-
ходной нейрон соответствует одному классу. Такой способ позволяет при клас-
сификации определять вероятность каждого класса по величине на выходе со-
ответствующего нейрона (чем ближе к единице, тем вероятность больше).
         Обучение персептрона проводится с помощью алгоритма обратного рас-
пространения ошибки, который минимизирует среднеквадратичную ошибку
нейронной сети. Для этого с целью настройки синаптических связей использу-
ется метод градиентного спуска в пространстве весовых коэффициентов и по-
рогов нейронной сети. Рассмотрим алгоритм обратного распространения
ошибки.
         1. На первом этапе происходит начальная инициализация знаний сети.
Простейший вариант такой инициализации – присвоить всем весам и порогам
случайные значения из диапазона [-1,1].
         2. Далее для каждой пары векторов (xr, yr) выполняется следующее:
         2.1. Для входного вектора рассчитываются выходы нейронов скрытого
слоя и выходы сети по формулам (3.1), (3.2).
         2.2. Происходит коррекция знаний сети, при этом главное значение имеет
отклонение реально полученного выхода сети y от идеального вектора yr. Со-
гласно методу градиентного спуска, изменение весовых коэффициентов и по-
рогов нейронной сети происходит по следующим формулам:

                                         E
       w jk (t  1)  w jk (t )                   ,                                    (3.3)
                                       w jk (t )

                                    E
       Tk (t  1)  Tk (t )                 ,                                          (3.4)
                                   Tk (t )


14
где E - среднеквадратичная ошибка нейронной сети для одного образа, а  –
параметр, определяющий скорость обучения. Формулы записаны в терминах
выходного слоя, аналогично выглядят формулы для скрытого слоя. Средне-
квадратичная ошибка сети вычисляется как

         1 m r
      E   ( yk  yk ) 2 .                                                  (3.5)
         2 k 1

Ошибка k-го нейрона выходного слоя определяется как

             E
      dk         ykr  yk .                                                (3.6)
             yk

Выразим производные из формул (3.3), (3.4) через легко вычисляемые величи-
ны. Определим взвешенную сумму, аргумент функции активации как

              h
      Sk     w jk g j  Tk .                                               (3.7)
             j 1

                             E
Из соотношения (3.3)              можно представить как:
                            w jk


       E      E  yk  S k
                               ,                                            (3.8)
       w jk  y k  S k  w jk

    E                                                 yk
где       d k  y kr  y k – ошибка k-го нейрона;          f (S ) – производная
     yk                                               Sk
                           Sk
функции активации;               g j – значение j-го нейрона предыдущего слоя.
                          w jk
Получаем

       E
              d k f ( S k ) g j .                                          (3.9)
       w jk

                                                 Sk
      Аналогично (3.8), с учетом того, что            1 , получаем
                                                 Tk




                                                                                15
       E  E  yk  S k
                            d k f ( S k ) .                                      (3.10)
       Tk  y k  S k  Tk

      Веса и пороги скрытого слоя также корректируются по формулам, анало-
гичным (3.3), (3.4), с учетом (3.9) и (3.10). При этом главной трудностью явля-
ется определение ошибки нейрона скрытого слоя. Эту ошибку явно определить
по формуле, аналогичной (3.6), нельзя, однако существует возможность рас-
считать ее через ошибки нейронов выходного слоя (отсюда произошло назва-
ние алгоритма обратного распространения ошибки):

           E    m E  y S             m
      ej                     k    k   d k f ( S k ) w jk .                    (3.11)
           g j k  1  y k  S k  g j k  1

      Производные от функций активации тоже легко рассчитываются, напри-
мер, для сигмоидной функции получаем

                                    
                         1       
      f ( S k )                  f ( S k )(1  f ( S k ))  y k (1  y k ) .   (3.12)
                    (1  e  S ) 
                                 

Аналогично:

      th( S k )  1  yk2 ;
                         
      
           2          
                       
                     1 
                                 
                           1  yk 2
                                    .
                                         
       (1  e  x )         2
                      

      Таким образом, можно записать окончательные выражения (3.3), (3.4)
для двух слоев, использующих сигмоидную функцию:

      w jk  w jk  y k (1  y k )d k g j ,                                        (3.13)

      Tk  Tk  y k (1  y k )d k ,                                                (3.14)

      vij  vij  g j (1  g j )e j xi ,                                           (3.15)

      Q j  Q j  g j (1  g j )e j .                                              (3.16)




16
      В эти формулы вводится дополнительный параметр –  – скорость обу-
чения скрытого слоя, который может отличаться от аналогичного параметра
для выходного слоя. Рекомендуется изменять скорости обучения обратно про-
порционально количеству шагов 2 алгоритма обучения, однако это не всегда
оправдывает себя на практике.
      3. После того, как коррекция знаний произведена для каждой пары век-
торов, можно оценить степень успешности обучения сети для определения мо-
мента завершения алгоритма. Для этого можно использовать в качестве крите-
рия максимальную по модулю ошибку на выходе dk, полученную на шаге 2.
Условием прекращения обучения в этом случае будет

     max d k  D, k  1, m, r  1, p ,                                (3.17)

где D – достаточно маленькая константа – величина максимальной ошибки, ко-
торую требуется достичь в процессе обучения. Если условие (3.17) не выполня-
ется, то шаг 2 повторяется.
       Способность персептрона-классификатора разделять образы в простран-
стве признаков прежде всего зависит от его скрытого слоя. Именно на этот
слой возлагается задача сделать множество классов линейно разделимым для
успешной работы выходного слоя. Очевидно, что чем больше нейронов в
скрытом слое, тем большее количество примеров этот слой может разделять.
Кроме этого, увеличение числа признаков входных образов также способствует
успешному их разделению в пространстве признаков. Однако увеличение этих
параметров приводит к росту ошибок сети и времени обучения. Увеличение
размерности входов n приводит к росту ошибки аппроксимации сети, возника-
ющей из-за обобщения данных. Увеличение числа нейронов h скрытого слоя
приводит к росту ошибки, связанной со сложностью модели. Персептрону лег-
че провести функцию через эталонные точки, однако при этом обобщающая
способность сети ухудшается. Он хуже предсказывает поведение аппроксими-
руемой функции на образах, не входящих в обучающую выборку. Такое состо-
яние сети называется переобучением.
       Оптимальное соотношение между этими параметрами оценивают как

           p
     h~      .                                                        (3.18)
           n

      Эксперименты показывают, что обучение максимально успешно прохо-
дит на множестве классов, хорошо (желательно линейно) разделенных в про-
странстве признаков. Это достигается удачным подбором информативных при-
знаков. Если классы в пространстве признаков хорошо кластеризуются, т.е. об-
разы каждого класса составляют компактную группу, достаточно удаленную от
других групп, то есть возможность уменьшить размер обучающей выборки p


                                                                          17
(используются только центры кластеров) и затем уменьшить число нейронов h.
Это приводит к ускорению обучения и улучшает работу классификатора.
      Другой проблемой является то, что алгоритм градиентного спуска не га-
рантирует нахождение глобального минимума среднеквадратичной ошибки се-
ти (3.5), а гарантируется определение только локального минимума. Проблемы,
возникающие в процессе градиентного спуска, можно проанализировать на
примере функции ошибки, схематически изображенной на рис. 3.2.


                       E

                                       B




                                           C
                             A                     D
                                                          W

                    Рис. 3.2. Схематическая функция ошибки сети

      На рис. 3.2 показаны четыре критические точки, производная функции
ошибки в которых близка к нулю. Точка A соответствует локальному миниму-
му. Признаком достижения локального минимума в процессе обучения являет-
ся полное прекращение уменьшения ошибки (3.17). В этом случаем может по-
мочь повторное обучение с другим начальным распределением знаний (тут
может помочь случайная инициализация). Точка B – локальный максимум. В
случае попадания в окрестность такой точки скорость резко падает, затем снова
быстро растет. Не существует способа предсказать, в какую сторону лучше
двигаться из точки с производной, близкой к нулю. Точка C – точка перегиба,
характеризуется длительным уменьшением скорости. Точка D – глобальный
минимум – цель алгоритма.
      Существуют многочисленные способы оптимизации метода градиентно-
го спуска, призванные улучшить поведение алгоритма в подобных критических
точках. Эффективной модификацией является введение момента, накапливаю-
щего влияние градиента на веса со временем. Тогда величина w (3.3) в момент
времени t будет вычисляться как

                   E
      w(t )         w(t  1) ,                                   (3.19)
                   w




18
где  - параметр, определяющий величину влияния момента. С использованием
(3.19) скорость изменения весов возрастает на участках с постоянным знаком
производной. В окрестностях минимума скорость резко падает за счет колеба-
ния знака.
      Достоинства алгоритма – большая скорость в точках перегиба, возмож-
ность по инерции преодолевать небольшие локальные минимумы. Недостат-
ки – еще один параметр, величину которого следует подбирать и настраивать.
      Этот и другие алгоритмы оптимизации обучения персептрона позволяют
улучшить работу сети в условиях плохой сходимости. Однако они усложняют
процесс обучения, не гарантируя в то же время полного успеха во всех случаях.
Успех обучения классификатора зависит от самого алгоритма обучения и каче-
ства обучающей выборки.


                                 3. Задание

      1. Ознакомьтесь с теоретической частью.
      2. На языке С, С++ напишите программу, реализующую многослойный
персептрон.
      3. Произведите обучение многослойного персептрона. Исходные данные
- 5 классов образов, размер идеального образа 6×6 (в соответствии с вариан-
том).
      4. Подайте на вход сети ряд тестовых образов, по 3 зашумленных образа
каждого из 5 классов.
      5. Проанализируйте результаты работы программы, которые должны
иметь следующий вид:
    вывести распознаваемый зашумленный образ.




   вывести процент подобия распознаваемого зашумленного образа по от-
    ношению к каждому из 5 классов.




                                                                           19
      вывести количество шагов, затраченных на обучение сети на заданное
       количество классов.
       6.Напишите отчет.
       Содержание отчета:
      топология многослойного персептрона;
      основные формулы обучения и воспроизведения;
      идеальные образы для обучения многослойного персептрона;
      тестовые зашумленные образы;
      результаты воспроизведения: процент подобия по отношению к каждому
       из классов, количество шагов, затраченных на обучение;
      результаты сравнения многослойного персептрона с нейронной сетью
       Хопфилда;
      выводы: преимущества и недостатки многослойного персептрона.


                                                                  Таблица 3.1
                              Варианты задания
№ варианта    1-ый класс   2-ой класс   3-ий класс   4-ый класс   5 класс
    1             2             3            4           5           7
    2             N             F            I           P           D
    3                                                            
    4                                                            
    5                                                            
    6             L            U            T            O           K
    7                                                            



                           4. Контрольные вопросы

       1. Топология многослойного персептрона.
       2. Процесс обучения.
       3. Процесс воспроизведения.
       4. Процедура обратного распространения ошибки.
       5. Каким образом можно улучшить качество распознавания?
       6. Достоинства и недостатки данного типа нейронной сети.




20
                       Лабораторная работа № 3
                              Сеть РБФ
                                1. Цель работы

     Изучение топологии, алгоритма функционирования сети РБФ.

                            2. Теоретические сведения

      Сеть РБФ (радиальная базисная функция) является аналогом многослой-
ного персептрона (рис. 4.1). Скорость обучения такой сети гораздо выше, при-
чем допускается полностью аналитический подход к расчету весовых коэффи-
циентов. Однако эти положительные моменты сопровождаются рядом недо-
статков, главным из которых является ухудшение точности аппроксимации.
Сеть обладает хорошей обобщающей способностью только для ограниченного
класса аппроксимируемых функций. В качестве классификатора такая сеть мо-
жет с успехом применяться в случае хорошей кластеризации классов в про-
странстве признаков.

               x1                                           y1
                      x1                           

               x2                                           y2
                      x2                           
                      ...             ...          ...
               xn                                           ym
                      xn                           
                        Рис. 4.1. Топология сети РБФ

      Упрощение работы и обучения достигается за счет введения вместо
скрытого слоя нейронов слоя РБФ ячеек. Классический закон, по которому та-
кая ячейка функционирует, определяется формулой гауссового колокола:

                      2
                xt j 
      g j  exp        ,                                             (4.1)
                 2j   
                       
                       

где x – входной вектор; t j – вектор, определяющий математическое ожидание
(центр кластера в пространстве признаков) РБФ ячейки; j – среднеквадратиче-
ское отклонение или параметр, зависящий от величины разброса образов клас-


                                                                          21
са от его центра (рис. 4.1). В данном выражении евклидово расстояние между
векторами x и t j вычисляется как

               2
      xt j         ( x1  t1j ) 2  ( x 2  t 2j ) 2  ...  ( xn  t nj ) 2 .

      Обучение. РБФ ячейки обучаются путем подбора центра и отклонения
каждой из них. Для классификатора в качестве центра выбирается центр кла-
стера в пространстве признаков, компактно содержащего образы одного и того
же класса. В простейшем случае, если класс задается одним идеальным обра-
зом, этот образ и будет являться вектором t – центром РБФ ячейки. Параметр
разброса каждой ячейки выбирается в зависимости от величины радиуса кла-
стера или расстояния до соседних центров. Ряд авторов рекомендует выбирать
 как половину расстояния до ближайшего центра ячейки, соответствующей
другому классу. Количество РБФ ячеек выбирается таким образом, чтобы по-
крыть гауссовыми колоколами все классы.

                                               1.5



                               ( x 10) 2
                           exp                1
                                     2
                              5           
                               ( x 10) 2
                           exp            
                                     2         0.5
                              2           


                                                     0   10            20
                                                          x

                           Рис. 4.2. Примеры функций РБФ ячеек
                        с одинаковым центром и разным разбросом

     Выходной слой РБФ сети обычно состоит из суммирующих ячеек

               h
      yk      w jk g j .                                                         (4.2)
              j 1

      Это позволяет при определенных условиях использовать систему линей-
ных уравнений для определения весов выходного слоя. В других обстоятель-
ствах можно использовать алгоритм градиентного спуска для настройки весов
выходного слоя (функция активации в данном случае линейная). С учетом того,
что обучается только выходной слой нейронной сети, а скрытый уже настроен,
обучение такой сети проходит на порядок быстрее, чем аналогичного много-
слойного персептрона.


22
     В случае обучения выходного слоя по алгоритму градиентного спуска
формулы расчета из лабораторной работы 2.2 значительно упрощаются. Фор-
мулы (3.1) и (3.2) заменяются соответственно на (4.1) и (4.2). Формула (3.13)
упрощается до

      w jk  w jk  d k g j ,                                          (4.3)

поскольку функция активации в выходном слое сети РБФ линейная и ее произ-
водная равна 1. Для коррекции весовых коэффициентов выходных суммирую-
щих ячеек используется только (4.3).
      Контроль завершения алгоритма обучения производится аналогично.
      Воспроизведение. Сеть функционирует по формулам (4.1) и (4.2).
      Очевидно, что функция на выходе РБФ сети будет представлять собой
суперпозицию гауссовых колоколов. В этом заключается ограничение данного
класса классификаторов. Кроме этого, при неудачном выборе признаков боль-
шой проблемой является выбор количества РБФ ячеек, определение их центров
и отклонения. С уменьшением числа РБФ ячеек улучшается обобщение данных
сетью, но могут проявляться большие ошибки в эталонных точках.


                                 3. Задание

      1. Ознакомьтесь с теоретической частью.
      2. Написать программу на С, С++, реализующую сеть РБФ.
      3. Произведите обучение сети РБФ. Исходные данные - 5 классов обра-
зов, размер идеального образа 6×6 (в соответствии с вариантом).
      4. Подайте на вход сети ряд тестовых образов, по 3 зашумленных образа
каждого из 5 классов.
      5. Проанализируйте результаты работы программы, которые должны
иметь следующий вид:
    вывести распознаваемый зашумленный образ;




   вывести процент подобия распознаваемого зашумленного образа по от-
    ношению к каждому из 5 классов;




                                                                           23
      вывести количество шагов, затраченных на обучение сети на заданное
       количество классов.
       6.Напишите отчет.
       Содержание отчета:
      топология сети РБФ;
      основные формулы обучения и воспроизведения;
      идеальные образы для обучения сети РБФ;
      тестовые зашумленные образы;
      результаты воспроизведения: процент подобия по отношению к каждому
       из классов, количество шагов, затраченных на обучение;
      результаты сравнения сети РБФ с многослойным персептроном;
      выводы: преимущества и недостатки сети РБФ.


                                                                  Таблица 4.1
                              Варианты задания
№ варианта    1-ый класс   2-ой класс   3-ий класс   4-ый класс   5 класс
    1             2             3            4           5           7
    2             N             F            I           P           D
    3                                                            
    4                                                            
    5                                                            
    6             L            U            T            O           K
    7                                                            



                           4. Контрольные вопросы

       1. Топология сети РБФ.
       2. Обучение сети, выбор количества РБФ ячеек.
       3. Процесс воспроизведения информации в сети РБФ.
       4. Каким образом можно улучшить работу сети?
       5. Достоинства и недостатки данного типа нейронной сети.



24
                       Лабораторная работа № 4
                     Конкурентная нейронная сеть
                                     1. Цель работы

     Изучение топологии, алгоритма функционирования конкурентной
нейронной сети.

                               2. Теоретические сведения

      Самоорганизующиеся нейронные сети обучаются без учителя. Они спо-
собны адаптироваться к входным данным, используя содержащиеся в этих
данных зависимости. Такие сети используются для нахождения более компакт-
ного описания данных (сжатия), кластеризации, выделения признаков.
      Конкурентная сеть является простейшей самоорганизующейся нейронной
сетью (рис. 5.1).


                               x1            wij       y1
                                         1         1
                                         …




                                                   …



                               xi                      yj
                                         i         j
                                         …




                                                   …




                               xn                      ym
                                         n         m
                       Рис. 5.1. Конкурентная нейронная сеть

     Первый слой является распределительным. Нейроны второго слоя функ-
ционируют по формуле

              n
      yj     wij xi  w j   x cos ,                                       (5.1)
             i 1

где x=(x1, x2,…,xi,…,xn) – входной вектор; w j=(w1j, w2j,…,wij,…,wnj ) – вектор ве-
совых коэффициентов нейрона, а | x | и |w j| – их модули,  – угол между ними.
      Обучение. При обучении нейронной сети при подаче каждого входного
вектора определяется нейрон-победитель, для которого (5.1) максимально. Для
этого нейрона синаптические связи усиливаются по формуле




                                                                                 25
     wij(t+1)=wij(t)+(xi-wij(t)),                                    (5.2)

где  – скорость обучения.
      Смысл этой формулы в том, что вектор весовых коэффициентов нейро-
на – победителя “поворачивается” в сторону входного вектора, тем самым ак-
тивность нейрона усиливается. Удобно работать с нормированными входными
и весовыми векторами, когда их модуль равен 1. Нормировка уравнивает шан-
сы в конкуренции нейронов с разным модулем вектора весовых коэффициен-
тов. Выражение (5.1) для нормированных векторов будет выглядеть как

              n
      yj     wij xi  cos ,                                        (5.3)
             i 1

а выражение (5.2):

                      wij (t )   ( xi  wij (t ))
      wij (t  1)                                    .               (5.4)
                         j                  j
                      w (t )   ( x  w (t ))

      Случайное начальное распределение весовых коэффициентов может при-
вести к тому, что некоторые нейроны никогда не станут победителями, так как
их весовые векторы окажутся удаленными от всех входных векторов. Суще-
ствует ряд модификаций алгоритма обучения, позволяющих устранить этот не-
достаток. Хорошие результаты на практике показало частотно–зависимое кон-
курентное обучение. Согласно нему, нейрон-победитель определяется по ми-
нимуму произведения евклидового расстояния между входным и весовым век-
тором и количеством побед данного нейрона fj:

      d v  min ( x  w j f j ) .                                     (5.5)
               j

      Шансы нейрона на победу уменьшаются с количеством побед, что дает
преимущество другим нейронам.
      Конкурентное обучение продолжается до тех пор, пока максимум евкли-
дового расстояния между любым входным вектором и соответствующим ему
вектором весов нейрона-победителя не достигнет заданного малого значения.
      Конкурентная сеть позволяет разбить входную выборку нормированных
векторов на m (количество выходных нейронов сети) кластеров, расположен-
ных на поверхности гиперсферы в пространстве признаков единичного радиу-
са. Входные векторы, приводящие к победе одного и того же нейрона, относят
к одному кластеру.



26
      Кохонен предложил внести в правило конкурентного обучения (5.2) ин-
формацию о расположении нейронов в выходном слое. Для этого нейроны
упорядочиваются в одномерные или двухмерные решетки. Вводится функция,
корректирующая изменение весов в зависимости от расстояния до нейрона–
победителя h(t,k,j) – сила влияния между нейроном–победителем k и нейроном
j в момент времени t. Для j=k эта функция всегда равна 1 и уменьшается с ро-
стом расстояния между k и j в решетке. С течением времени радиус влияния
обычно сужается. С использованием этой функции веса меняются для всех
нейронов сети, а не только для нейрона-победителя:

     wij(t+1)=wij(t)+ h(t,k,j)(xi-wij(t)).                            (5.6)


       В качестве функции h(t,k,j) может использоваться гауссовый колокол
(4.1) с параметром , зависящим от времени или функция вида “мексиканская
шляпа”.

                                              h(t,k,j)




                                                         Расстояние


            Рис. 5.2. Пример функции расстояния в сетях Кохонена

     В результате модификации конкурентного обучения сеть Кохонена не
только кластеризирует входные примеры, но и упорядочивает их в виде одно-
мерной или двухмерной решетки. Это позволяет получить дополнительную
информацию о близости кластеров. Если два кластера проецируются на сосед-
ние нейроны решетки, это говорит об их близости в исходном пространстве
признаков. Обратное неверно. Из-за уменьшения размерности пространства
отношение близости сохраняется только для ограниченного числа кластеров.


                                      3. Задание

     1. Ознакомьтесь с теоретической частью.



                                                                          27
      2. Написать программу на С, С++, реализующую конкурентную нейрон-
   ную сеть.
      3. Обучить конкурентную сеть с использованием правила (5.5) на количе-
ство образов, превышающих количество нейронов сети. Рекомендуется исполь-
зовать нормированные векторы. Исходные данные - 5 классов образов, размер
идеального образа 6×6 (в соответствии с вариантом).
      4. Убедиться, что похожие образы были спроецированы сетью в один
кластер (подача их на вход активизирует один и тот же нейрон).
      5. Подать на вход тестовые образы, отличные от образов из обучающей
выборки. Сделать выводы.
      6.Напишите отчет.
      Содержание отчета:
    топология конкурентной нейронной сети;
    основные формулы обучения и воспроизведения;
    идеальные образы для обучения сети;
    тестовые зашумленные образы;
    результаты воспроизведения;
    результаты сравнения конкурентной нейронной сети с сетью РБФ и мно-
      гослойным персептроном;
    выводы: преимущества и недостатки конкурентной нейронной сети.


                                                                 Таблица 5.1
                             Варианты задания
№ варианта   1-ый класс   2-ой класс   3-ий класс   4-ый класс   5 класс
    1            2             3            4           5           7
    2            N             F            I           P           D
    3                                                           
    4                                                           
    5                                                           
    6            L            U            T            O           K
    7                                                           



                          4. Контрольные вопросы

        1. Смысл самообучения.
        2. Обучение конкурентной нейронной сети.
        3. Определение нейрона-победителя.
        4. Сеть Кохонена.
        5. Использование самоорганизующихся сетей.
        6. Достоинства и недостатки данного типа нейронной сети.



28
                                  Литература


1. Aleksander I., Morton H. An Introduction to Neural Computing. — London:
   Chapman&Hall, 1990.
2. Головко В.А. Нейронные сети: обучение, организация и применение. Учеб.
   пособие для вузов.– М.:ИПРЖР, 2001. – 256 с.
3. Bishop C.M. Neural Networks for Pattern Recognition.– Oxford: Clarendon
   press, 1995.– 482 p.
4. Hopfield J.J. Neural networks and physical systems with emergent collective
   computational abilities // Proc. Natl. Acad. Sci. USA.– 1982.– Vol. 79.– P. 2554.
5. Kohonen T. Self-organization and associative memory. – Springer-Verlag, 1989.–
   312 p.
6. Kohonen T. Self-organized formation of topologically correct feature maps // Bi-
   ol. Cybernetics.– 1982.– Vol. 43.– P. 56-69.
7. Kohonen T. Self-organizing maps. –Springer-Verlag, 1995.– 362 p.
8. Rumelhart D.E., Hinton G.E., Wiliams R.J. Learning internal representation by
   error propagation: McClelland J.L. and Rumelhart D.E. (Eds). Parallel Distributed
   Processing: Exploration in the Microstructure of Cognition.– MIT Press, Cam-
   bridge MA.– 1986.– Vol. 1.– P. 318-362.
9. Хайкин С. Нейронные сети: полный курс, 2-е изд.: Пер. с англ. — М. : Изда-
   тельский дом «Вильямс», 2006. — 1104 с.
10.Ежов А.А., Шумский С.А. Нейрокомпьютинг и его применение в экономике
   и бизнесе. –М.: Мир, 1998.– 222 c.




                                                                                  29
